{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nptsne\n",
    "from nptsne import hsne_analysis\n",
    "import multiscale_phate as mp\n",
    "\n",
    "import time\n",
    "import os\n",
    "import scprep\n",
    "import demap\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import humap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import normalize, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fmnist():\n",
    "    fashionTrain = pd.read_csv('./../data/fashion-train.csv')\n",
    "\n",
    "    fashionX = fashionTrain.values[:,2:]\n",
    "    fashionY = fashionTrain.values[:, 1].astype(int)\n",
    "\n",
    "    X = normalize(fashionX)\n",
    "    y = fashionY\n",
    "#     X = PCA(n_components=15).fit_transform(X)\n",
    "    X = check_array(X, dtype=np.float32, accept_sparse='csr', order='C')\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def load_mnist():\n",
    "    X = np.load('./../data/MNIST_70000.npy')\n",
    "    y = np.load('./../data/MNIST_70000_label.npy').astype(int)\n",
    "    X = normalize(X)\n",
    "#     X = PCA(n_components=15).fit_transform(X)\n",
    "    X = check_array(X, dtype=np.float32, accept_sparse='csr', order='C')\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def load_scRNAseq():\n",
    "    download_path = os.path.expanduser(\"~/Documentos/HierarchicalUMAP/umap-cpp/umap/cpp/data\")\n",
    "    sparse=True\n",
    "    T1 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T0_1A\"), sparse=sparse, gene_labels='both')\n",
    "    T2 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T2_3B\"), sparse=sparse, gene_labels='both')\n",
    "    T3 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T4_5C\"), sparse=sparse, gene_labels='both')\n",
    "    T4 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T6_7D\"), sparse=sparse, gene_labels='both')\n",
    "    T5 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T8_9E\"), sparse=sparse, gene_labels='both')\n",
    "    filtered_batches = []\n",
    "    for batch in [T1, T2, T3, T4, T5]:\n",
    "        batch = scprep.filter.filter_library_size(batch, percentile=20, keep_cells='above')\n",
    "        batch = scprep.filter.filter_library_size(batch, percentile=75, keep_cells='below')\n",
    "        filtered_batches.append(batch)\n",
    "    del T1, T2, T3, T4, T5\n",
    "    EBT_counts, sample_labels = scprep.utils.combine_batches(\n",
    "        filtered_batches, \n",
    "        [\"Day 00-03\", \"Day 06-09\", \"Day 12-15\", \"Day 18-21\", \"Day 24-27\"],\n",
    "        append_to_cell_names=True\n",
    "    )\n",
    "    del filtered_batches # removes objects from memory\n",
    "    EBT_counts = scprep.filter.filter_rare_genes(EBT_counts, min_cells=10)\n",
    "    EBT_counts = scprep.normalize.library_size_normalize(EBT_counts)\n",
    "    mito_genes = scprep.select.get_gene_set(EBT_counts, starts_with=\"MT-\") # Get all mitochondrial genes. There are 14, FYI.\n",
    "    EBT_counts, sample_labels = scprep.filter.filter_gene_set_expression(\n",
    "    EBT_counts, sample_labels, genes=mito_genes, \n",
    "    percentile=90, keep_cells='below')\n",
    "    EBT_counts = scprep.transform.sqrt(EBT_counts)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(sample_labels)\n",
    "    labels = le.transform(sample_labels)\n",
    "    X = PCA(n_components=50).fit_transform(EBT_counts.values)\n",
    "    X = check_array(X, dtype=np.float32, accept_sparse='csr', order='C')\n",
    "    return X, labels\n",
    "\n",
    "def load_mammals():\n",
    "    X = np.loadtxt(\"./../data/mammals-20000_features.txt\")\n",
    "    y = np.loadtxt(\"./../data/mammals-20000_classes.txt\")\n",
    "    X = normalize(X)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mnist-np dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Initing at 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [37:18<00:00, 319.80s/it]\n"
     ]
    }
   ],
   "source": [
    "n_executions = 20\n",
    "levels = 3\n",
    "\n",
    "df_humapTOP_0 = pd.DataFrame()\n",
    "df_humapLevel1_0 = pd.DataFrame()\n",
    "df_humapLevel0_0 = pd.DataFrame()\n",
    "\n",
    "df_humapTOP_30 = pd.DataFrame()\n",
    "df_humapLevel1_30 = pd.DataFrame()\n",
    "df_humapLevel0_30 = pd.DataFrame()\n",
    "\n",
    "df_humapTOP_50 = pd.DataFrame()\n",
    "df_humapLevel1_50 = pd.DataFrame()\n",
    "df_humapLevel0_50 = pd.DataFrame()\n",
    "\n",
    "df_humapTOP_70 = pd.DataFrame()\n",
    "df_humapLevel1_70 = pd.DataFrame()\n",
    "df_humapLevel0_70 = pd.DataFrame()\n",
    "\n",
    "df_humapTOP_100 = pd.DataFrame()\n",
    "df_humapLevel1_100 = pd.DataFrame()\n",
    "df_humapLevel0_100 = pd.DataFrame()\n",
    "\n",
    "df_hsneTOP = pd.DataFrame()\n",
    "df_hsneLevel1 = pd.DataFrame()\n",
    "df_hsneLevel0 = pd.DataFrame()\n",
    "\n",
    "datasets = []\n",
    "\n",
    "# datasets.append({\n",
    "#    'load': load_scRNAseq,\n",
    "#    'name': 'scRNAseq'\n",
    "# })\n",
    "# datasets.append({\n",
    "#    'load': load_mammals,\n",
    "#    'name': 'mammals-drill'\n",
    "# })\n",
    "# datasets.append({\n",
    "#     'load': load_fmnist,\n",
    "#     'name': 'fmnist-drill'\n",
    "# })\n",
    "datasets.append({\n",
    "    'load': load_mnist,\n",
    "    'name': 'mnist-np'\n",
    "})\n",
    "    \n",
    "    \n",
    "for dataset in datasets:\n",
    "    print(\"Loading %s dataset...\" % (dataset['name']))\n",
    "    X, y = dataset['load']()\n",
    "    print(\"Done.\")\n",
    "    init = 0\n",
    "\n",
    "    if not os.path.exists(\"comparison-np/\"+dataset['name']):\n",
    "        os.mkdir(\"comparison-np/\"+dataset['name'])\n",
    "        \n",
    "        \n",
    "    for i in range(n_executions):\n",
    "        if os.path.exists('comparison-np/'+dataset['name']+'/humap100_it'+str(i)+'_level0.csv'):\n",
    "            init = i+1\n",
    "          \n",
    "                \n",
    "    print(\"Initing at %d\" % (init))\n",
    "\n",
    "        \n",
    "    level2 = 0\n",
    "    for execution in tqdm(range(init, n_executions)):\n",
    "        \n",
    "        time_file = open(\"comparison-np/\"+dataset['name']+'/run-time.csv', 'a')\n",
    "\n",
    "        hsne = nptsne.HSne(True)\n",
    "        tic = time.time()\n",
    "        hsne.create_hsne(X, 3)\n",
    "        execution_hsne_fit = time.time()-tic\n",
    "\n",
    "        n_level0 = hsne.get_scale(0).num_points\n",
    "        n_level1 = hsne.get_scale(1).num_points\n",
    "        n_level2 = hsne.get_scale(2).num_points\n",
    "\n",
    "        \n",
    "        \n",
    "     \n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "            Executing HSNE in CPU\n",
    "        \"\"\"\n",
    "        tic = time.time()\n",
    "        container = hsne_analysis.AnalysisModel(hsne, hsne_analysis.EmbedderType.GPU)\n",
    "        analysis_level2 = container.top_analysis\n",
    "        for i in range(500):\n",
    "            analysis_level2.do_iteration()\n",
    "        execution_hsne_top = (time.time()-tic)\n",
    "        \n",
    "        tic = time.time()\n",
    "        analysis_level1 = container.add_new_analysis(analysis_level2, np.arange(n_level2))\n",
    "        for i in range(500):\n",
    "            analysis_level1.do_iteration()\n",
    "        execution_hsne_level1 = (time.time()-tic)\n",
    "        \n",
    "        tic = time.time()\n",
    "        analysis_level0 = container.add_new_analysis(analysis_level1, np.arange(n_level1))\n",
    "        for i in range(500):\n",
    "            analysis_level0.do_iteration()\n",
    "\n",
    "        execution_hsne_level0 = (time.time()-tic)\n",
    "\n",
    "\n",
    "        df_hsneTOP['label'+str(execution)] = y[analysis_level2.landmark_orig_indexes]\n",
    "        df_hsneTOP['x'+str(execution)] = analysis_level2.embedding[:, 0]\n",
    "        df_hsneTOP['y'+str(execution)] = analysis_level2.embedding[:, 1]\n",
    "        df_hsneTOP['inds'+str(execution)] = analysis_level2.landmark_orig_indexes\n",
    "        \n",
    "        df_hsneLevel1['label'+str(execution)] = y[analysis_level1.landmark_orig_indexes]\n",
    "        df_hsneLevel1['x'+str(execution)] = analysis_level1.embedding[:, 0]\n",
    "        df_hsneLevel1['y'+str(execution)] = analysis_level1.embedding[:, 1]\n",
    "        df_hsneLevel1['inds'+str(execution)] = analysis_level1.landmark_orig_indexes\n",
    "\n",
    "        df_hsneLevel0['label'+str(execution)] = y[analysis_level0.landmark_orig_indexes]\n",
    "        df_hsneLevel0['x'+str(execution)] = analysis_level0.embedding[:, 0]\n",
    "        df_hsneLevel0['y'+str(execution)] = analysis_level0.embedding[:, 1]\n",
    "        df_hsneLevel0['inds'+str(execution)] = analysis_level0.landmark_orig_indexes\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "            Executing HUMAP0\n",
    "        \"\"\"\n",
    "        \n",
    "        hUmap0 = humap.HUMAP(np.array([n_level1/n_level0, n_level2/n_level1]))\n",
    "        hUmap0.set_distance_similarity(False)\n",
    "        hUmap0.set_path_increment(False)\n",
    "        hUmap0.set_influence_neighborhood(0)\n",
    "        \n",
    "        tic = time.time()\n",
    "        hUmap0.fit(X, y)\n",
    "        execution_humap0_fit = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding2 = hUmap0.transform(2)\n",
    "        execution_humap0_top = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding1 = hUmap0.transform(1)\n",
    "        execution_humap0_level1 = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding0 = hUmap0.transform(0)\n",
    "        execution_humap0_level0 = time.time() - tic\n",
    "\n",
    "\n",
    "        df_humapTOP_0['label'+str(execution)] = hUmap0.labels(2)\n",
    "        df_humapTOP_0['x'+str(execution)] = embedding2[:, 0]\n",
    "        df_humapTOP_0['y'+str(execution)] = embedding2[:, 1]\n",
    "        df_humapTOP_0['inds'+str(execution)] = hUmap0.original_indices(2)\n",
    "        \n",
    "        df_humapLevel1_0['label'+str(execution)] = hUmap0.labels(1)\n",
    "        df_humapLevel1_0['x'+str(execution)] = embedding1[:, 0]\n",
    "        df_humapLevel1_0['y'+str(execution)] = embedding1[:, 1]\n",
    "        df_humapLevel1_0['inds'+str(execution)] = hUmap0.original_indices(1)\n",
    "\n",
    "        df_humapLevel0_0['label'+str(execution)] = y\n",
    "        df_humapLevel0_0['x'+str(execution)] = embedding0[:, 0]\n",
    "        df_humapLevel0_0['y'+str(execution)] = embedding0[:, 1]\n",
    "        df_humapLevel0_0['inds'+str(execution)] = np.arange(len(y))\n",
    "        \n",
    "        \"\"\"\n",
    "            Executing HUMAP30\n",
    "        \"\"\"\n",
    "        \n",
    "        hUmap30 = humap.HUMAP(np.array([n_level1/n_level0, n_level2/n_level1]))\n",
    "        hUmap30.set_distance_similarity(False)\n",
    "        hUmap30.set_path_increment(False)\n",
    "        hUmap30.set_influence_neighborhood(30)\n",
    "        \n",
    "        tic = time.time()\n",
    "        hUmap30.fit(X, y)\n",
    "        execution_humap30_fit = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding2 = hUmap30.transform(2)\n",
    "        execution_humap30_top = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding1 = hUmap30.transform(1)\n",
    "        execution_humap30_level1 = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding0 = hUmap30.transform(0)\n",
    "        execution_humap30_level0 = time.time() - tic\n",
    "\n",
    "\n",
    "        df_humapTOP_30['label'+str(execution)] = hUmap30.labels(2)\n",
    "        df_humapTOP_30['x'+str(execution)] = embedding2[:, 0]\n",
    "        df_humapTOP_30['y'+str(execution)] = embedding2[:, 1]\n",
    "        df_humapTOP_30['inds'+str(execution)] = hUmap30.original_indices(2)\n",
    "        \n",
    "        df_humapLevel1_30['label'+str(execution)] = hUmap30.labels(1)\n",
    "        df_humapLevel1_30['x'+str(execution)] = embedding1[:, 0]\n",
    "        df_humapLevel1_30['y'+str(execution)] = embedding1[:, 1]\n",
    "        df_humapLevel1_30['inds'+str(execution)] = hUmap30.original_indices(1)\n",
    "\n",
    "        df_humapLevel0_30['label'+str(execution)] = y\n",
    "        df_humapLevel0_30['x'+str(execution)] = embedding0[:, 0]\n",
    "        df_humapLevel0_30['y'+str(execution)] = embedding0[:, 1]\n",
    "        df_humapLevel0_30['inds'+str(execution)] = np.arange(len(y))\n",
    "        \n",
    "        \"\"\"\n",
    "            Executing HUMAP50\n",
    "        \"\"\"\n",
    "        \n",
    "        hUmap50 = humap.HUMAP(np.array([n_level1/n_level0, n_level2/n_level1]))\n",
    "        hUmap50.set_distance_similarity(False)\n",
    "        hUmap50.set_path_increment(False)\n",
    "        hUmap50.set_influence_neighborhood(50)\n",
    "        \n",
    "        tic = time.time()\n",
    "        hUmap50.fit(X, y)\n",
    "        execution_humap50_fit = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding2 = hUmap50.transform(2)\n",
    "        execution_humap50_top = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding1 = hUmap50.transform(1)\n",
    "        execution_humap50_level1 = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding0 = hUmap50.transform(0)\n",
    "        execution_humap50_level0 = time.time() - tic\n",
    "\n",
    "\n",
    "        df_humapTOP_50['label'+str(execution)] = hUmap50.labels(2)\n",
    "        df_humapTOP_50['x'+str(execution)] = embedding2[:, 0]\n",
    "        df_humapTOP_50['y'+str(execution)] = embedding2[:, 1]\n",
    "        df_humapTOP_50['inds'+str(execution)] = hUmap50.original_indices(2)\n",
    "\n",
    "        df_humapLevel1_50['label'+str(execution)] = hUmap50.labels(1)\n",
    "        df_humapLevel1_50['x'+str(execution)] = embedding1[:, 0]\n",
    "        df_humapLevel1_50['y'+str(execution)] = embedding1[:, 1]\n",
    "        df_humapLevel1_50['inds'+str(execution)] = hUmap50.original_indices(1)\n",
    "        \n",
    "        df_humapLevel0_50['label'+str(execution)] = y\n",
    "        df_humapLevel0_50['x'+str(execution)] = embedding0[:, 0]\n",
    "        df_humapLevel0_50['y'+str(execution)] = embedding0[:, 1]\n",
    "        df_humapLevel0_50['inds'+str(execution)] = np.arange(len(y))\n",
    "        \n",
    "        \"\"\"\n",
    "            Executing HUMAP70\n",
    "        \"\"\"\n",
    "        \n",
    "        hUmap70 = humap.HUMAP(np.array([n_level1/n_level0, n_level2/n_level1]))\n",
    "        hUmap70.set_distance_similarity(False)\n",
    "        hUmap70.set_path_increment(False)\n",
    "        hUmap70.set_influence_neighborhood(70)\n",
    "        \n",
    "        tic = time.time()\n",
    "        hUmap70.fit(X, y)\n",
    "        execution_humap70_fit = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding2 = hUmap70.transform(2)\n",
    "        execution_humap70_top = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding1 = hUmap70.transform(1)\n",
    "        execution_humap70_level1 = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding0 = hUmap70.transform(0)\n",
    "        execution_humap70_level0 = time.time() - tic\n",
    "\n",
    "\n",
    "        df_humapTOP_70['label'+str(execution)] = hUmap70.labels(2)\n",
    "        df_humapTOP_70['x'+str(execution)] = embedding2[:, 0]\n",
    "        df_humapTOP_70['y'+str(execution)] = embedding2[:, 1]\n",
    "        df_humapTOP_70['inds'+str(execution)] = hUmap70.original_indices(2)\n",
    "\n",
    "        df_humapLevel1_70['label'+str(execution)] = hUmap70.labels(1)\n",
    "        df_humapLevel1_70['x'+str(execution)] = embedding1[:, 0]\n",
    "        df_humapLevel1_70['y'+str(execution)] = embedding1[:, 1]\n",
    "        df_humapLevel1_70['inds'+str(execution)] = hUmap70.original_indices(1)\n",
    "        \n",
    "        df_humapLevel0_70['label'+str(execution)] = y\n",
    "        df_humapLevel0_70['x'+str(execution)] = embedding0[:, 0]\n",
    "        df_humapLevel0_70['y'+str(execution)] = embedding0[:, 1]\n",
    "        df_humapLevel0_70['inds'+str(execution)] = np.arange(len(y))\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "            Executing HUMAP100\n",
    "        \"\"\"\n",
    "        \n",
    "        hUmap100 = humap.HUMAP(np.array([n_level1/n_level0, n_level2/n_level1]))\n",
    "        hUmap100.set_distance_similarity(False)\n",
    "        hUmap100.set_path_increment(False)\n",
    "        hUmap100.set_influence_neighborhood(100)\n",
    "        \n",
    "        tic = time.time()\n",
    "        hUmap100.fit(X, y)\n",
    "        execution_humap100_fit = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding2 = hUmap100.transform(2)\n",
    "        execution_humap100_top = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding1 = hUmap100.transform(1)\n",
    "        execution_humap100_level1 = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding0 = hUmap100.transform(0)\n",
    "        execution_humap100_level0 = time.time() - tic\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        df_humapTOP_100['label'+str(execution)] = hUmap100.labels(2)\n",
    "        df_humapTOP_100['x'+str(execution)] = embedding2[:, 0]\n",
    "        df_humapTOP_100['y'+str(execution)] = embedding2[:, 1]\n",
    "        df_humapTOP_100['inds'+str(execution)] = hUmap100.original_indices(2)\n",
    "\n",
    "        df_humapLevel1_100['label'+str(execution)] = hUmap100.labels(1)\n",
    "        df_humapLevel1_100['x'+str(execution)] = embedding1[:, 0]\n",
    "        df_humapLevel1_100['y'+str(execution)] = embedding1[:, 1]\n",
    "        df_humapLevel1_100['inds'+str(execution)] = hUmap100.original_indices(1)\n",
    "        \n",
    "        df_humapLevel0_100['label'+str(execution)] = y\n",
    "        df_humapLevel0_100['x'+str(execution)] = embedding0[:, 0]\n",
    "        df_humapLevel0_100['y'+str(execution)] = embedding0[:, 1]\n",
    "        df_humapLevel0_100['inds'+str(execution)] = np.arange(len(y))\n",
    "        \n",
    "        \n",
    "        df_hsneTOP.to_csv(\"comparison-np/\"+dataset['name']+'/hsne_it'+str(execution)+'_TOP.csv', index=False)\n",
    "        df_hsneLevel1.to_csv(\"comparison-np/\"+dataset['name']+'/hsne_it'+str(execution)+'_level1.csv', index=False)\n",
    "        df_hsneLevel0.to_csv(\"comparison-np/\"+dataset['name']+'/hsne_it'+str(execution)+'_level0.csv', index=False)\n",
    "        \n",
    "        df_humapTOP_0.to_csv(\"comparison-np/\"+dataset['name']+'/humap0_it'+str(execution)+'_TOP.csv', index=False)\n",
    "        df_humapLevel1_0.to_csv(\"comparison-np/\"+dataset['name']+'/humap0_it'+str(execution)+'_level1.csv', index=False)\n",
    "        df_humapLevel0_0.to_csv(\"comparison-np/\"+dataset['name']+'/humap0_it'+str(execution)+'_level0.csv', index=False)\n",
    "        \n",
    "        df_humapTOP_30.to_csv(\"comparison-np/\"+dataset['name']+'/humap30_it'+str(execution)+'_TOP.csv', index=False)\n",
    "        df_humapLevel1_30.to_csv(\"comparison-np/\"+dataset['name']+'/humap30_it'+str(execution)+'_level1.csv', index=False)\n",
    "        df_humapLevel0_30.to_csv(\"comparison-np/\"+dataset['name']+'/humap30_it'+str(execution)+'_level0.csv', index=False)\n",
    "        \n",
    "        df_humapTOP_50.to_csv(\"comparison-np/\"+dataset['name']+'/humap50_it'+str(execution)+'_TOP.csv', index=False)\n",
    "        df_humapLevel1_50.to_csv(\"comparison-np/\"+dataset['name']+'/humap50_it'+str(execution)+'_level1.csv', index=False)\n",
    "        df_humapLevel0_50.to_csv(\"comparison-np/\"+dataset['name']+'/humap50_it'+str(execution)+'_level0.csv', index=False)\n",
    "        \n",
    "        df_humapTOP_70.to_csv(\"comparison-np/\"+dataset['name']+'/humap70_it'+str(execution)+'_TOP.csv', index=False)\n",
    "        df_humapLevel1_70.to_csv(\"comparison-np/\"+dataset['name']+'/humap70_it'+str(execution)+'_level1.csv', index=False)\n",
    "        df_humapLevel0_70.to_csv(\"comparison-np/\"+dataset['name']+'/humap70_it'+str(execution)+'_level0.csv', index=False)\n",
    "        \n",
    "        df_humapTOP_100.to_csv(\"comparison-np/\"+dataset['name']+'/humap100_it'+str(execution)+'_TOP.csv', index=False)\n",
    "        df_humapLevel1_100.to_csv(\"comparison-np/\"+dataset['name']+'/humap100_it'+str(execution)+'_level1.csv', index=False)\n",
    "        df_humapLevel0_100.to_csv(\"comparison-np/\"+dataset['name']+'/humap100_it'+str(execution)+'_level0.csv', index=False)\n",
    "       \n",
    "        \n",
    "        df_humapTOP_0 = pd.DataFrame()\n",
    "        df_humapLevel1_0 = pd.DataFrame()\n",
    "        df_humapLevel0_0 = pd.DataFrame()\n",
    "\n",
    "        df_humapTOP_30 = pd.DataFrame()\n",
    "        df_humapLevel1_30 = pd.DataFrame()\n",
    "        df_humapLevel0_30 = pd.DataFrame()\n",
    "\n",
    "        df_humapTOP_50 = pd.DataFrame()\n",
    "        df_humapLevel1_50 = pd.DataFrame()\n",
    "        df_humapLevel0_50 = pd.DataFrame()\n",
    "\n",
    "        df_humapTOP_70 = pd.DataFrame()\n",
    "        df_humapLevel1_70 = pd.DataFrame()\n",
    "        df_humapLevel0_70 = pd.DataFrame()\n",
    "\n",
    "        df_humapTOP_100 = pd.DataFrame()\n",
    "        df_humapLevel1_100 = pd.DataFrame()\n",
    "        df_humapLevel0_100 = pd.DataFrame()\n",
    "\n",
    "        df_hsneTOP = pd.DataFrame()\n",
    "        df_hsneLevel1= pd.DataFrame()\n",
    "        df_hsneLevel0 = pd.DataFrame()\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        time_file.write('HSNE,Fit,'+str(execution_hsne_fit)+'\\n')\n",
    "        time_file.write('HUMAP 0,Fit,'+str(execution_humap0_fit)+'\\n')        \n",
    "        time_file.write('HUMAP 30,Fit,'+str(execution_humap30_fit)+'\\n') \n",
    "        time_file.write('HUMAP 50,Fit,'+str(execution_humap50_fit)+'\\n') \n",
    "        time_file.write('HUMAP 70,Fit,'+str(execution_humap70_fit)+'\\n') \n",
    "        time_file.write('HUMAP 100,Fit,'+str(execution_humap100_fit)+'\\n') \n",
    "        \n",
    "        \n",
    "        time_file.write('HSNE,Top,'+str(execution_hsne_top)+'\\n')\n",
    "        time_file.write('HUMAP 0,Top,'+str(execution_humap0_top)+'\\n')        \n",
    "        time_file.write('HUMAP 30,Top,'+str(execution_humap30_top)+'\\n') \n",
    "        time_file.write('HUMAP 50,Top,'+str(execution_humap50_top)+'\\n') \n",
    "        time_file.write('HUMAP 70,Top,'+str(execution_humap70_top)+'\\n') \n",
    "        time_file.write('HUMAP 100,Top,'+str(execution_humap100_top)+'\\n') \n",
    "        \n",
    "        time_file.write('HSNE,Level 1,'+str(execution_hsne_level1)+'\\n')\n",
    "        time_file.write('HUMAP 0,Level 1,'+str(execution_humap0_level1)+'\\n')        \n",
    "        time_file.write('HUMAP 30,Level 1,'+str(execution_humap30_level1)+'\\n') \n",
    "        time_file.write('HUMAP 50,Level 1,'+str(execution_humap50_level1)+'\\n') \n",
    "        time_file.write('HUMAP 70,Level 1,'+str(execution_humap70_level1)+'\\n') \n",
    "        time_file.write('HUMAP 100,Level 1,'+str(execution_humap100_level1)+'\\n')\n",
    "        \n",
    "        time_file.write('HSNE,Level 0,'+str(execution_hsne_level0)+'\\n')\n",
    "        time_file.write('HUMAP 0,Level 0,'+str(execution_humap0_level0)+'\\n')        \n",
    "        time_file.write('HUMAP 30,Level 0,'+str(execution_humap30_level0)+'\\n') \n",
    "        time_file.write('HUMAP 50,Level 0,'+str(execution_humap50_level0)+'\\n') \n",
    "        time_file.write('HUMAP 70,Level 0,'+str(execution_humap70_level0)+'\\n') \n",
    "        time_file.write('HUMAP 100,Level 0,'+str(execution_humap100_level0)+'\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testar HUMAP com FAISS, KDtree e FLANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_hsneCPU_level0['x0'].values, df_hsneCPU_level0['y0'].values, c=df_hsneCPU_level0['label0'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_hsneGPU_level2['x0'].values, df_hsneGPU_level2['y0'].values, c=df_hsneGPU_level2['label0'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_hsneGPU_level0['x0'].values, df_hsneGPU_level0['y0'].values, c=df_hsneGPU_level0['label0'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_humap_level2['x0'].values, df_humap_level2['y0'].values, c=df_humap_level2['label0'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_humap_level0['x0'].values, df_humap_level0['y0'].values, c=df_humap_level0['label0'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_mphate_level2['x0'].values, df_mphate_level2['y0'].values, c=df_mphate_level2['label0'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_mphate_level0['x0'].values, df_mphate_level0['y0'].values, c=df_mphate_level0['label0'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
