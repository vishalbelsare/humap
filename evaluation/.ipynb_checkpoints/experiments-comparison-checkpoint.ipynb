{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nptsne\n",
    "from nptsne import hsne_analysis\n",
    "import multiscale_phate as mp \n",
    "\n",
    "import time\n",
    "import os\n",
    "import scprep\n",
    "import demap\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import humap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import normalize, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fmnist():\n",
    "    fashionTrain = pd.read_csv('./../data/fashion-train.csv')\n",
    "\n",
    "    fashionX = fashionTrain.values[:,2:]\n",
    "    fashionY = fashionTrain.values[:, 1].astype(int)\n",
    "\n",
    "    X = normalize(fashionX)\n",
    "    y = fashionY\n",
    "    X = check_array(X, dtype=np.float32, accept_sparse='csr', order='C')\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def load_mnist():\n",
    "    X = np.load('./../data/MNIST_70000.npy')\n",
    "    y = np.load('./../data/MNIST_70000_label.npy').astype(int)\n",
    "    X = normalize(X)\n",
    "    X = check_array(X, dtype=np.float32, accept_sparse='csr', order='C')\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def load_scRNAseq():\n",
    "    download_path = os.path.expanduser(\"./../data\")\n",
    "    sparse=True\n",
    "    T1 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T0_1A\"), sparse=sparse, gene_labels='both')\n",
    "    T2 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T2_3B\"), sparse=sparse, gene_labels='both')\n",
    "    T3 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T4_5C\"), sparse=sparse, gene_labels='both')\n",
    "    T4 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T6_7D\"), sparse=sparse, gene_labels='both')\n",
    "    T5 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T8_9E\"), sparse=sparse, gene_labels='both')\n",
    "    filtered_batches = []\n",
    "    for batch in [T1, T2, T3, T4, T5]:\n",
    "        batch = scprep.filter.filter_library_size(batch, percentile=20, keep_cells='above')\n",
    "        batch = scprep.filter.filter_library_size(batch, percentile=75, keep_cells='below')\n",
    "        filtered_batches.append(batch)\n",
    "    del T1, T2, T3, T4, T5\n",
    "    EBT_counts, sample_labels = scprep.utils.combine_batches(\n",
    "        filtered_batches, \n",
    "        [\"Day 00-03\", \"Day 06-09\", \"Day 12-15\", \"Day 18-21\", \"Day 24-27\"],\n",
    "        append_to_cell_names=True\n",
    "    )\n",
    "    del filtered_batches # removes objects from memory\n",
    "    EBT_counts = scprep.filter.filter_rare_genes(EBT_counts, min_cells=10)\n",
    "    EBT_counts = scprep.normalize.library_size_normalize(EBT_counts)\n",
    "    mito_genes = scprep.select.get_gene_set(EBT_counts, starts_with=\"MT-\") # Get all mitochondrial genes. There are 14, FYI.\n",
    "    EBT_counts, sample_labels = scprep.filter.filter_gene_set_expression(\n",
    "    EBT_counts, sample_labels, genes=mito_genes, \n",
    "    percentile=90, keep_cells='below')\n",
    "    EBT_counts = scprep.transform.sqrt(EBT_counts)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(sample_labels)\n",
    "    labels = le.transform(sample_labels)\n",
    "    X = PCA(n_components=50).fit_transform(EBT_counts.values)\n",
    "    X = check_array(X, dtype=np.float32, accept_sparse='csr', order='C')\n",
    "    return X, labels\n",
    "\n",
    "def load_mammals():\n",
    "    X = np.loadtxt(\"./../data/mammals-20000_features.txt\")\n",
    "    y = np.loadtxt(\"./../data/mammals-20000_classes.txt\")\n",
    "    X = normalize(X)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fmnist dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Initing at 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [22:18<00:00, 334.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mnist dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Initing at 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [2:14:06<00:00, 402.34s/it]  \n"
     ]
    }
   ],
   "source": [
    "n_executions = 20\n",
    "levels = 3\n",
    "\n",
    "df_hsneCPU_level2 = pd.DataFrame()\n",
    "df_hsneCPU_level1 = pd.DataFrame()\n",
    "df_hsneCPU_level0 = pd.DataFrame()\n",
    "\n",
    "df_hsneGPU_level2 = pd.DataFrame()\n",
    "df_hsneGPU_level1 = pd.DataFrame()\n",
    "df_hsneGPU_level0 = pd.DataFrame()\n",
    "\n",
    "df_humap_level2 = pd.DataFrame()\n",
    "df_humap_level1 = pd.DataFrame()\n",
    "df_humap_level0 = pd.DataFrame()\n",
    "\n",
    "df_mphate_level2 = pd.DataFrame()\n",
    "df_mphate_level1 = pd.DataFrame()\n",
    "df_mphate_level0 = pd.DataFrame()\n",
    "\n",
    "datasets = []\n",
    "\n",
    "# datasets.append({\n",
    "#    'load': load_scRNAseq,\n",
    "#    'name': 'scRNAseq'\n",
    "# })\n",
    "# datasets.append({\n",
    "#    'load': load_mammals,\n",
    "#    'name': 'mammals'\n",
    "# })\n",
    "datasets.append({\n",
    "    'load': load_fmnist,\n",
    "    'name': 'fmnist'\n",
    "})\n",
    "datasets.append({\n",
    "    'load': load_mnist,\n",
    "    'name': 'mnist'\n",
    "})\n",
    "    \n",
    "    \n",
    "for dataset in datasets:\n",
    "    print(\"Loading %s dataset...\" % (dataset['name']))\n",
    "    X, y = dataset['load']()\n",
    "    print(\"Done.\")\n",
    "\n",
    "    init = 0\n",
    "    \n",
    "    if not os.path.exists(\"comparison-techniques/\"):\n",
    "        os.mkdir(\"comparison-techniques\")\n",
    "    \n",
    "    \n",
    "\n",
    "    if not os.path.exists(\"comparison-techniques/\"+dataset['name']):\n",
    "        os.mkdir(\"comparison-techniques/\"+dataset['name'])\n",
    "        \n",
    "        \n",
    "    for i in range(n_executions):\n",
    "        if os.path.exists('comparison-techniques/'+dataset['name']+'/humap_it'+str(i)+'_level0.csv'):\n",
    "            init = i+1\n",
    "          \n",
    "                \n",
    "    print(\"Initing at %d\" % (init))\n",
    "\n",
    "        \n",
    "    level2 = 0\n",
    "    for execution in tqdm(range(init, n_executions)):\n",
    "        \n",
    "        time_file = open(\"comparison-techniques/\"+dataset['name']+'/run-time.csv', 'a')\n",
    "        size_file = open(\"comparison-techniques/\"+dataset['name']+'/mphate_size_level2.csv', 'a')\n",
    "\n",
    "        hsneCPU = nptsne.HSne(True)\n",
    "        tic = time.time()\n",
    "        hsneCPU.create_hsne(X, 3)\n",
    "        execution_hsneCPU_fit = time.time()-tic\n",
    "\n",
    "        hsneGPU = nptsne.HSne(True)\n",
    "        tic = time.time()\n",
    "        hsneGPU.create_hsne(X, 3)\n",
    "        execution_hsneGPU_fit = time.time()-tic\n",
    "\n",
    "        n_level0 = hsneGPU.get_scale(0).num_points\n",
    "        n_level1 = hsneGPU.get_scale(1).num_points\n",
    "        n_level2 = hsneGPU.get_scale(2).num_points\n",
    "\n",
    "        hUmap = humap.HUMAP(np.array([n_level1/n_level0, n_level2/n_level1]))\n",
    "        hUmap.set_influence_neighborhood(0)\n",
    "        hUmap.set_fixing_term(0.01)\n",
    "        \n",
    "        executed_mphate = False\n",
    "        \n",
    "        if dataset['name'] != 'mnist' and dataset['name'] != 'fmnist':\n",
    "            mp_op = mp.Multiscale_PHATE(n_jobs=10)\n",
    "\n",
    "            \"\"\"\n",
    "                Executing Multiscale PHATE\n",
    "            \"\"\"\n",
    "\n",
    "            execution_mphate = -1\n",
    "#             try: \n",
    "            tic = time.time()\n",
    "            levels = mp_op.fit(X)\n",
    "            execution_mphate_fit = time.time()-tic\n",
    "\n",
    "\n",
    "            level2 = 0\n",
    "            dif = np.abs(len(np.unique(mp_op.NxTs[0])) - n_level2)\n",
    "            for level in range(len(levels)):\n",
    "                d = np.abs(len(np.unique(mp_op.NxTs[level])) - n_level2)\n",
    "                if d < dif:\n",
    "                    dif = d\n",
    "                    level2 = level\n",
    "            print(\"level: %d, n: %d, dif: %d\" % (level2, len(np.unique(mp_op.NxTs[level2])), len(np.unique(mp_op.NxTs[level2]))-n_level2))\n",
    "\n",
    "            tic = time.time()\n",
    "            embedding2, _, _ = mp_op.transform(level2, level2)\n",
    "            execution_mphate_level2 = (time.time()-tic)\n",
    "            \n",
    "            level1 = 0\n",
    "            dif = np.abs(len(np.unique(mp_op.NxTs[0])) - n_level1)\n",
    "            for level in range(len(levels)):\n",
    "                d = np.abs(len(np.unique(mp_op.NxTs[level])) - n_level1)\n",
    "                if d < dif:\n",
    "                    dif = d\n",
    "                    level1 = level\n",
    "            print(\"level: %d, n: %d, dif: %d\" % (level1, len(np.unique(mp_op.NxTs[level1])), len(np.unique(mp_op.NxTs[level1]))-n_level1))\n",
    "\n",
    "            tic = time.time()\n",
    "            embedding1, _, _ = mp_op.transform(level1, level1)\n",
    "            execution_mphate_level1 = (time.time()-tic)\n",
    "\n",
    "            tic = time.time()\n",
    "            embedding0, _, _ = mp_op.transform(0, 0)\n",
    "            execution_mphate_level0 = (time.time()-tic)\n",
    "\n",
    "            df_mphate_level2['label'+str(execution)] = y[np.unique(mp_op.NxTs[level2])]\n",
    "            df_mphate_level2['x'+str(execution)] = embedding2[:, 0]\n",
    "            df_mphate_level2['y'+str(execution)] = embedding2[:, 1]\n",
    "            df_mphate_level2['inds'+str(execution)] = np.unique(mp_op.NxTs[level2])\n",
    "            \n",
    "            df_mphate_level1['label'+str(execution)] = y[np.unique(mp_op.NxTs[level1])]\n",
    "            df_mphate_level1['x'+str(execution)] = embedding1[:, 0]\n",
    "            df_mphate_level1['y'+str(execution)] = embedding1[:, 1]\n",
    "            df_mphate_level1['inds'+str(execution)] = np.unique(mp_op.NxTs[level1])\n",
    "\n",
    "            df_mphate_level0['label'+str(execution)] = y\n",
    "            df_mphate_level0['x'+str(execution)] = embedding0[:, 0]\n",
    "            df_mphate_level0['y'+str(execution)] = embedding0[:, 1]\n",
    "            df_mphate_level0['inds'+str(execution)] = np.arange(len(y))\n",
    "\n",
    "            df_mphate_level2.to_csv(\"comparison-techniques/\"+dataset['name']+'/mphate_it'+str(execution)+'_level2.csv', index=False)\n",
    "            df_mphate_level1.to_csv(\"comparison-techniques/\"+dataset['name']+'/mphate_it'+str(execution)+'_level1.csv', index=False)\n",
    "            df_mphate_level0.to_csv(\"comparison-techniques/\"+dataset['name']+'/mphate_it'+str(execution)+'_level0.csv', index=False)\n",
    "            executed_mphate = True\n",
    "#             except:\n",
    "#                 executed_mphate = False\n",
    "#                 print((\"Could not compute Multiscale PHATE embeddings.\"))\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "            Executing HSNE in CPU\n",
    "        \"\"\"\n",
    "        tic = time.time()\n",
    "        container = hsne_analysis.AnalysisModel(hsneCPU, hsne_analysis.EmbedderType.CPU)\n",
    "        analysis_level2 = container.top_analysis\n",
    "        for i in range(500):\n",
    "            analysis_level2.do_iteration()\n",
    "        execution_hsneCPU_level2 = (time.time()-tic)\n",
    "\n",
    "        tic = time.time()\n",
    "        analysis_level1 = container.add_new_analysis(analysis_level2, np.arange(n_level2))\n",
    "        for i in range(500):\n",
    "            analysis_level1.do_iteration()\n",
    "        execution_hsneCPU_level1 = (time.time()-tic)\n",
    "        \n",
    "        tic = time.time()\n",
    "        analysis_level0 = container.add_new_analysis(analysis_level1, np.arange(n_level1))\n",
    "        for i in range(500):\n",
    "            analysis_level0.do_iteration()\n",
    "\n",
    "        execution_hsneCPU_level0 = (time.time()-tic)\n",
    "\n",
    "\n",
    "        df_hsneCPU_level2['label'+str(execution)] = y[analysis_level2.landmark_orig_indexes]\n",
    "        df_hsneCPU_level2['x'+str(execution)] = analysis_level2.embedding[:, 0]\n",
    "        df_hsneCPU_level2['y'+str(execution)] = analysis_level2.embedding[:, 1]\n",
    "        df_hsneCPU_level2['inds'+str(execution)] = analysis_level2.landmark_orig_indexes\n",
    "        \n",
    "        df_hsneCPU_level1['label'+str(execution)] = y[analysis_level1.landmark_orig_indexes]\n",
    "        df_hsneCPU_level1['x'+str(execution)] = analysis_level1.embedding[:, 0]\n",
    "        df_hsneCPU_level1['y'+str(execution)] = analysis_level1.embedding[:, 1]\n",
    "        df_hsneCPU_level1['inds'+str(execution)] = analysis_level1.landmark_orig_indexes\n",
    "\n",
    "        df_hsneCPU_level0['label'+str(execution)] = y[analysis_level0.landmark_orig_indexes]\n",
    "        df_hsneCPU_level0['x'+str(execution)] = analysis_level0.embedding[:, 0]\n",
    "        df_hsneCPU_level0['y'+str(execution)] = analysis_level0.embedding[:, 1]\n",
    "        df_hsneCPU_level0['inds'+str(execution)] = analysis_level0.landmark_orig_indexes\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "            Executing HSNE in GPU\n",
    "        \"\"\"\n",
    "        tic = time.time()\n",
    "        container = hsne_analysis.AnalysisModel(hsneGPU, hsne_analysis.EmbedderType.GPU)\n",
    "        analysis_level2 = container.top_analysis\n",
    "        for i in range(500):\n",
    "            analysis_level2.do_iteration()\n",
    "        execution_hsneGPU_level2 = (time.time()-tic) \n",
    "    \n",
    "        tic = time.time()\n",
    "        analysis_level1 = container.add_new_analysis(analysis_level2, np.arange(n_level2))\n",
    "        for i in range(500):\n",
    "            analysis_level1.do_iteration()\n",
    "        execution_hsneGPU_level1 = (time.time()-tic) \n",
    "        \n",
    "        tic = time.time()\n",
    "        analysis_level0 = container.add_new_analysis(analysis_level1, np.arange(n_level1))\n",
    "        for i in range(500):\n",
    "            analysis_level0.do_iteration()\n",
    "\n",
    "        execution_hsneGPU_level0 = (time.time()-tic) \n",
    "\n",
    "\n",
    "        df_hsneGPU_level2['label'+str(execution)] = y[analysis_level2.landmark_orig_indexes]\n",
    "        df_hsneGPU_level2['x'+str(execution)] = analysis_level2.embedding[:, 0]\n",
    "        df_hsneGPU_level2['y'+str(execution)] = analysis_level2.embedding[:, 1]\n",
    "        df_hsneGPU_level2['inds'+str(execution)] = analysis_level2.landmark_orig_indexes\n",
    "        \n",
    "        df_hsneGPU_level1['label'+str(execution)] = y[analysis_level1.landmark_orig_indexes]\n",
    "        df_hsneGPU_level1['x'+str(execution)] = analysis_level1.embedding[:, 0]\n",
    "        df_hsneGPU_level1['y'+str(execution)] = analysis_level1.embedding[:, 1]\n",
    "        df_hsneGPU_level1['inds'+str(execution)] = analysis_level1.landmark_orig_indexes\n",
    "\n",
    "        df_hsneGPU_level0['label'+str(execution)] = y[analysis_level0.landmark_orig_indexes]\n",
    "        df_hsneGPU_level0['x'+str(execution)] = analysis_level0.embedding[:, 0]\n",
    "        df_hsneGPU_level0['y'+str(execution)] = analysis_level0.embedding[:, 1]\n",
    "        df_hsneGPU_level0['inds'+str(execution)] = analysis_level0.landmark_orig_indexes\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "            Executing HUMAP\n",
    "        \"\"\"\n",
    "        tic = time.time()\n",
    "        hUmap.fit(X, y)\n",
    "        execution_humap_fit = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding2 = hUmap.transform(2)\n",
    "        execution_humap_level2 = time.time() - tic\n",
    "        \n",
    "        hUmap.fix_datapoints(embedding2)        \n",
    "        tic = time.time()\n",
    "        embedding1 = hUmap.transform(1)\n",
    "        execution_humap_level1 = time.time() - tic\n",
    "        \n",
    "        hUmap.fix_datapoints(embedding1)\n",
    "        tic = time.time()\n",
    "        embedding0 = hUmap.transform(0)\n",
    "        execution_humap_level0 = time.time() - tic\n",
    "\n",
    "\n",
    "        df_humap_level2['label'+str(execution)] = hUmap.labels(2)\n",
    "        df_humap_level2['x'+str(execution)] = embedding2[:, 0]\n",
    "        df_humap_level2['y'+str(execution)] = embedding2[:, 1]\n",
    "        df_humap_level2['inds'+str(execution)] = hUmap.original_indices(2)\n",
    "        \n",
    "        df_humap_level1['label'+str(execution)] = hUmap.labels(1)\n",
    "        df_humap_level1['x'+str(execution)] = embedding1[:, 0]\n",
    "        df_humap_level1['y'+str(execution)] = embedding1[:, 1]\n",
    "        df_humap_level1['inds'+str(execution)] = hUmap.original_indices(1)\n",
    "\n",
    "        df_humap_level0['label'+str(execution)] = y\n",
    "        df_humap_level0['x'+str(execution)] = embedding0[:, 0]\n",
    "        df_humap_level0['y'+str(execution)] = embedding0[:, 1]\n",
    "        df_humap_level0['inds'+str(execution)] = np.arange(len(y))\n",
    "\n",
    "        df_hsneCPU_level2.to_csv(\"comparison-techniques/\"+dataset['name']+'/hsneCPU_it'+str(execution)+'_level2.csv', index=False)\n",
    "        df_hsneCPU_level1.to_csv(\"comparison-techniques/\"+dataset['name']+'/hsneCPU_it'+str(execution)+'_level1.csv', index=False)\n",
    "        df_hsneCPU_level0.to_csv(\"comparison-techniques/\"+dataset['name']+'/hsneCPU_it'+str(execution)+'_level0.csv', index=False)\n",
    "        df_hsneGPU_level2.to_csv(\"comparison-techniques/\"+dataset['name']+'/hsneGPU_it'+str(execution)+'_level2.csv', index=False)\n",
    "        df_hsneGPU_level1.to_csv(\"comparison-techniques/\"+dataset['name']+'/hsneGPU_it'+str(execution)+'_level1.csv', index=False)\n",
    "        df_hsneGPU_level0.to_csv(\"comparison-techniques/\"+dataset['name']+'/hsneGPU_it'+str(execution)+'_level0.csv', index=False)\n",
    "        df_humap_level2.to_csv(\"comparison-techniques/\"+dataset['name']+'/humap_it'+str(execution)+'_level2.csv', index=False)\n",
    "        df_humap_level1.to_csv(\"comparison-techniques/\"+dataset['name']+'/humap_it'+str(execution)+'_level1.csv', index=False)\n",
    "        df_humap_level0.to_csv(\"comparison-techniques/\"+dataset['name']+'/humap_it'+str(execution)+'_level0.csv', index=False)\n",
    "        \n",
    "        df_hsneCPU_level2 = pd.DataFrame()\n",
    "        df_hsneCPU_level1 = pd.DataFrame()\n",
    "        df_hsneCPU_level0 = pd.DataFrame()\n",
    "\n",
    "        df_hsneGPU_level2 = pd.DataFrame()\n",
    "        df_hsneGPU_level1 = pd.DataFrame()\n",
    "        df_hsneGPU_level0 = pd.DataFrame()\n",
    "\n",
    "        df_humap_level2 = pd.DataFrame()\n",
    "        df_humap_level1 = pd.DataFrame()\n",
    "        df_humap_level0 = pd.DataFrame()\n",
    "\n",
    "        df_mphate_level2 = pd.DataFrame()\n",
    "        df_mphate_level1 = pd.DataFrame()\n",
    "        df_mphate_level0 = pd.DataFrame()\n",
    "\n",
    "        \n",
    "        \n",
    "        time_file.write('HSNE CPU,Fit,'+str(execution_hsneCPU_fit)+'\\n')\n",
    "        time_file.write('HSNE GPU,Fit,'+str(execution_hsneGPU_fit)+'\\n')\n",
    "        time_file.write('HUMAP,Fit,'+str(execution_humap_fit)+'\\n')        \n",
    "        \n",
    "        time_file.write('HSNE CPU,Level 2,'+str(execution_hsneCPU_level2)+'\\n')\n",
    "        time_file.write('HSNE GPU,Level 2,'+str(execution_hsneGPU_level2)+'\\n')\n",
    "        time_file.write('HUMAP,Level 2,'+str(execution_humap_level2)+'\\n')\n",
    "        \n",
    "        time_file.write('HSNE CPU,Level 1,'+str(execution_hsneCPU_level1)+'\\n')\n",
    "        time_file.write('HSNE GPU,Level 1,'+str(execution_hsneGPU_level1)+'\\n')\n",
    "        time_file.write('HUMAP,Level 1,'+str(execution_humap_level1)+'\\n')\n",
    "        \n",
    "        time_file.write('HSNE CPU,Level 0,'+str(execution_hsneCPU_level0)+'\\n')\n",
    "        time_file.write('HSNE GPU,Level 0,'+str(execution_hsneGPU_level0)+'\\n')\n",
    "        time_file.write('HUMAP,Level 0,'+str(execution_humap_level0)+'\\n')\n",
    "        \n",
    "        \n",
    "        if executed_mphate:\n",
    "            time_file.write('Multiscale PHATE,Fit,'+str(execution_mphate_level2)+'\\n')\n",
    "            time_file.write('Multiscale PHATE,Level 2,'+str(execution_mphate_level2)+'\\n')\n",
    "            time_file.write('Multiscale PHATE,Level 1,'+str(execution_mphate_level1)+'\\n')\n",
    "            time_file.write('Multiscale PHATE,Level 0,'+str(execution_mphate_level0)+'\\n')\n",
    "            size_file.write(str(level2)+','+str(len(np.unique(mp_op.NxTs[level2])))+'\\n')\n",
    "            size_file.write(str(level1)+','+str(len(np.unique(mp_op.NxTs[level1])))+'\\n')\n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "        size_file.close()\n",
    "        time_file.close()\n",
    "          \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
