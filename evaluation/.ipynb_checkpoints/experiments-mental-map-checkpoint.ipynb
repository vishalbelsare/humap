{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import humap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial import procrustes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions to load datasets\n",
    "def load_fmnist():\n",
    "    fashionTrain = pd.read_csv('./../data/fashion-train.csv')\n",
    "\n",
    "    fashionX = fashionTrain.values[:,2:]\n",
    "    fashionY = fashionTrain.values[:, 1].astype(int)\n",
    "\n",
    "    X = normalize(fashionX)\n",
    "    y = fashionY\n",
    "    X = check_array(X, dtype=np.float32, accept_sparse='csr', order='C')\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def load_mnist():\n",
    "    X = np.load('./../data/MNIST_70000.npy')\n",
    "    y = np.load('./../data/MNIST_70000_label.npy').astype(int)\n",
    "    X = normalize(X)\n",
    "    X = check_array(X, dtype=np.float32, accept_sparse='csr', order='C')\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def load_scRNAseq():\n",
    "    download_path = os.path.expanduser(\"./../data\")\n",
    "    sparse=True\n",
    "    T1 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T0_1A\"), sparse=sparse, gene_labels='both')\n",
    "    T2 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T2_3B\"), sparse=sparse, gene_labels='both')\n",
    "    T3 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T4_5C\"), sparse=sparse, gene_labels='both')\n",
    "    T4 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T6_7D\"), sparse=sparse, gene_labels='both')\n",
    "    T5 = scprep.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T8_9E\"), sparse=sparse, gene_labels='both')\n",
    "    filtered_batches = []\n",
    "    for batch in [T1, T2, T3, T4, T5]:\n",
    "        batch = scprep.filter.filter_library_size(batch, percentile=20, keep_cells='above')\n",
    "        batch = scprep.filter.filter_library_size(batch, percentile=75, keep_cells='below')\n",
    "        filtered_batches.append(batch)\n",
    "    del T1, T2, T3, T4, T5\n",
    "    EBT_counts, sample_labels = scprep.utils.combine_batches(\n",
    "        filtered_batches, \n",
    "        [\"Day 00-03\", \"Day 06-09\", \"Day 12-15\", \"Day 18-21\", \"Day 24-27\"],\n",
    "        append_to_cell_names=True\n",
    "    )\n",
    "    del filtered_batches # removes objects from memory\n",
    "    EBT_counts = scprep.filter.filter_rare_genes(EBT_counts, min_cells=10)\n",
    "    EBT_counts = scprep.normalize.library_size_normalize(EBT_counts)\n",
    "    mito_genes = scprep.select.get_gene_set(EBT_counts, starts_with=\"MT-\") # Get all mitochondrial genes. There are 14, FYI.\n",
    "    EBT_counts, sample_labels = scprep.filter.filter_gene_set_expression(\n",
    "    EBT_counts, sample_labels, genes=mito_genes, \n",
    "    percentile=90, keep_cells='below')\n",
    "    EBT_counts = scprep.transform.sqrt(EBT_counts)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(sample_labels)\n",
    "    labels = le.transform(sample_labels)\n",
    "    X = PCA(n_components=50).fit_transform(EBT_counts.values)\n",
    "    X = check_array(X, dtype=np.float32, accept_sparse='csr', order='C')\n",
    "    return X, labels\n",
    "\n",
    "def load_mammals():\n",
    "    X = np.loadtxt(\"./../data/mammals-20000_features.txt\")\n",
    "    y = np.loadtxt(\"./../data/mammals-20000_classes.txt\")\n",
    "    X = normalize(X)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "# datasets.append({\n",
    "#    'load': load_scRNAseq,\n",
    "#    'name': 'scRNAseq'\n",
    "# })\n",
    "\n",
    "datasets.append({\n",
    "   'load': load_mammals,\n",
    "   'name': 'mammals'\n",
    "})\n",
    "\n",
    "# datasets.append({\n",
    "#     'load': load_fmnist,\n",
    "#     'name': 'fmnist'\n",
    "# })\n",
    "\n",
    "# datasets.append({\n",
    "#     'load': load_mnist,\n",
    "#     'name': 'mnist'\n",
    "# })\n",
    "\n",
    "n_executions = 20\n",
    "levels = 3\n",
    "\n",
    "\n",
    "def select_landmarks(values_level, values_next_level):    \n",
    "    intersect = []\n",
    "    \n",
    "    for row in values_level:\n",
    "        pos, = np.where(index == values_next_level[:, -1])\n",
    "        if len(pos) > 0:\n",
    "            intersect.append(values_next_level[pos[0]][1:-1])\n",
    "    \n",
    "    return np.array(intersect)\n",
    "\n",
    "\n",
    "def plot_procrustes(embedding_a, embedding_b, y, disparity):\n",
    "    \n",
    "    f, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    ax[0].scatter(embedding_a[:, 0], embedding_a[:, 1], c=y, alpha=0.1, cmap='tab10')\n",
    "    ax[0].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False) \n",
    "    ax[0].tick_params(axis='y', which='both', left=False, right=False, labelleft=False) \n",
    "\n",
    "    ax[1].scatter(embedding_b[:, 0], embedding_b[:, 1], c=y, alpha=0.1, cmap='tab10')\n",
    "    ax[1].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False) \n",
    "    ax[1].tick_params(axis='y', which='both', left=False, right=False, labelleft=False) \n",
    "    \n",
    "    print(\"Disparity between embeddings: %.5f\" % (disparity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    name = dataset['name']\n",
    "    \n",
    "    for execution in tqdm(range(n_executions)):\n",
    "        \n",
    "        humap_values = []\n",
    "        for level in range(levels):\n",
    "            df = pd.read_csv('comparison-techniques/'+name+'/humap_it'+str(execution)+'_level'+str(levels-level)+'.csv')\n",
    "            humap_values.append(df.values)\n",
    "                    \n",
    "        humap_landmarks = []\n",
    "        for i in range(levels-1):\n",
    "            humap_landmarks.append(select_landmarks(humap_values[i], humap_values[i+1]))\n",
    "            \n",
    "        for i in range(len(humap_landmarks)):\n",
    "            mtx1, mtx2, disparity = procrustes(humap_values[i][:, 1:-1], humap_landmarks[i])\n",
    "            plot_procrustes(mtx1, mtx2, humap_values[i][:, 0], disparity)\n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
