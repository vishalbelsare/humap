{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nptsne\n",
    "from nptsne import hsne_analysis\n",
    "import multiscale_phate as mp\n",
    "\n",
    "import time\n",
    "import os\n",
    "import scprep\n",
    "import demap\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import humap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import normalize, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fmnist():\n",
    "    fashionTrain = pd.read_csv('./../data/fashion-train.csv')\n",
    "\n",
    "    fashionX = fashionTrain.values[:,2:]\n",
    "    fashionY = fashionTrain.values[:, 1].astype(int)\n",
    "\n",
    "    X = normalize(fashionX)\n",
    "    y = fashionY\n",
    "    X = check_array(X, dtype=np.float32, accept_sparse='csr', order='C')\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_mammals():\n",
    "    X = np.loadtxt(\"./../data/mammals-20000_features.txt\")\n",
    "    y = np.loadtxt(\"./../data/mammals-20000_classes.txt\")\n",
    "    X = normalize(X)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fmnist-drill dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Initing at 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:35<00:00, 47.97s/it]\n"
     ]
    }
   ],
   "source": [
    "n_executions = 20\n",
    "levels = 3\n",
    "\n",
    "df_humapTOP = pd.DataFrame()\n",
    "df_humapLevel1 = pd.DataFrame()\n",
    "df_humapLevel0 = pd.DataFrame()\n",
    "\n",
    "df_hsneTOP = pd.DataFrame()\n",
    "df_hsneLevel1 = pd.DataFrame()\n",
    "df_hsneLevel0 = pd.DataFrame()\n",
    "\n",
    "datasets = []\n",
    "\n",
    "\n",
    "# datasets.append({\n",
    "#    'load': load_mammals,\n",
    "#    'name': 'mammals-drill'\n",
    "# })\n",
    "datasets.append({\n",
    "    'load': load_fmnist,\n",
    "    'name': 'fmnist-drill'\n",
    "})\n",
    "    \n",
    "    \n",
    "for dataset in datasets:\n",
    "    print(\"Loading %s dataset...\" % (dataset['name']))\n",
    "    X, y = dataset['load']()\n",
    "    print(\"Done.\")\n",
    "    init = 0\n",
    "    \n",
    "    if not os.path.exists(\"comparison-drill/\"):\n",
    "        os.mkdir(\"comparison-drill\")\n",
    "\n",
    "    if not os.path.exists(\"comparison-drill/\"+dataset['name']):\n",
    "        os.mkdir(\"comparison-drill/\"+dataset['name'])\n",
    "        \n",
    "        \n",
    "    for i in range(n_executions):\n",
    "        if os.path.exists('comparison-drill/'+dataset['name']+'/humap_it'+str(i)+'_level0.csv'):\n",
    "            init = i+1\n",
    "          \n",
    "                \n",
    "    print(\"Initing at %d\" % (init))\n",
    "\n",
    "        \n",
    "    for execution in tqdm(range(init, n_executions)):\n",
    "        \n",
    "        time_file = open(\"comparison-drill/\"+dataset['name']+'/run-time.csv', 'a')\n",
    "\n",
    "        hsne = nptsne.HSne(True)\n",
    "        tic = time.time()\n",
    "        hsne.create_hsne(X, 3)\n",
    "        execution_hsne_fit = time.time()-tic\n",
    "\n",
    "        n_level0 = hsne.get_scale(0).num_points\n",
    "        n_level1 = hsne.get_scale(1).num_points\n",
    "        n_level2 = hsne.get_scale(2).num_points\n",
    "\n",
    "        hUmap = humap.HUMAP(np.array([n_level1/n_level0, n_level2/n_level1]))\n",
    "        hUmap.set_influence_neighborhood(0)\n",
    "        hUmap.set_fixing_term(0.01)\n",
    "     \n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "            Executing HSNE in CPU\n",
    "        \"\"\"\n",
    "        tic = time.time()\n",
    "        container = hsne_analysis.AnalysisModel(hsne, hsne_analysis.EmbedderType.GPU)\n",
    "        analysis_level2 = container.top_analysis\n",
    "        for i in range(500):\n",
    "            analysis_level2.do_iteration()\n",
    "        execution_hsneTOP = (time.time()-tic)\n",
    "        \n",
    "        y_analysis_level2 = y[analysis_level2.landmark_orig_indexes]\n",
    "        \n",
    "        classes = None\n",
    "        if dataset['name'] == 'mammals-drill':\n",
    "            classes = [1,2, 3]\n",
    "        else:\n",
    "            classes = [0,2,3,4,6,8]\n",
    "            \n",
    "        indices = []\n",
    "        for i in range(len(y_analysis_level2)):\n",
    "            if y_analysis_level2[i] in classes:\n",
    "                indices.append(i)\n",
    "        \n",
    "        tic = time.time()\n",
    "        analysis_cluster1 = container.add_new_analysis(analysis_level2, np.array(indices))\n",
    "        for i in range(500):\n",
    "            analysis_cluster1.do_iteration()\n",
    "        execution_hsneLevel1 = time.time()-tic\n",
    "        \n",
    "        y_analysis_cluster1 = y[analysis_cluster1.landmark_orig_indexes]\n",
    "        tic = time.time()\n",
    "        analysis_cluster0 = container.add_new_analysis(analysis_cluster1, np.arange(len(y_analysis_cluster1)))\n",
    "        for i in range(500):\n",
    "            analysis_cluster0.do_iteration()\n",
    "\n",
    "        execution_hsneLevel0 = (time.time()-tic)\n",
    "\n",
    "\n",
    "        df_hsneTOP['label'+str(execution)] = y[analysis_level2.landmark_orig_indexes]\n",
    "        df_hsneTOP['x'+str(execution)] = analysis_level2.embedding[:, 0]\n",
    "        df_hsneTOP['y'+str(execution)] = analysis_level2.embedding[:, 1]\n",
    "        df_hsneTOP['inds'+str(execution)] = analysis_level2.landmark_orig_indexes\n",
    "\n",
    "        df_hsneLevel1['label'+str(execution)] = y[analysis_cluster1.landmark_orig_indexes]\n",
    "        df_hsneLevel1['x'+str(execution)] = analysis_cluster1.embedding[:, 0]\n",
    "        df_hsneLevel1['y'+str(execution)] = analysis_cluster1.embedding[:, 1]\n",
    "        df_hsneLevel1['inds'+str(execution)] = analysis_cluster1.landmark_orig_indexes\n",
    "        \n",
    "        df_hsneLevel0['label'+str(execution)] = y[analysis_cluster0.landmark_orig_indexes]\n",
    "        df_hsneLevel0['x'+str(execution)] = analysis_cluster0.embedding[:, 0]\n",
    "        df_hsneLevel0['y'+str(execution)] = analysis_cluster0.embedding[:, 1]\n",
    "        df_hsneLevel0['inds'+str(execution)] = analysis_cluster0.landmark_orig_indexes\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "            Executing HUMAP\n",
    "        \"\"\"\n",
    "        tic = time.time()\n",
    "        hUmap.fit(X, y)\n",
    "        execution_humap_fit = time.time() - tic\n",
    "        \n",
    "        tic = time.time()\n",
    "        embedding2 = hUmap.transform(2)\n",
    "        execution_humapTOP = time.time() - tic\n",
    "        \n",
    "        \n",
    "        indices_class = []\n",
    "        labels2 = hUmap.labels(2)\n",
    "        datapoints = []\n",
    "        for i, label in enumerate(labels2):\n",
    "            if label in classes:\n",
    "                indices_class.append(i)\n",
    "                datapoints.append(embedding2[i])\n",
    "        \n",
    "        \n",
    "        \n",
    "        tic = time.time()\n",
    "        hUmap.fix_datapoints(datapoints)\n",
    "        \n",
    "        embedding_clusterLevel1, y_clusterLevel1, indices_cluster = hUmap.transform(2, indices=indices_class)#indices=np.array(classes), class_based=True)\n",
    "        orig_index = hUmap.original_indices(1)\n",
    "        inds_level1 = orig_index[indices_cluster]\n",
    "        execution_humapLevel1 = time.time() - tic\n",
    "        \n",
    "        \n",
    "        indices_class = []\n",
    "        datapoints = []\n",
    "        for i, label in enumerate(y_clusterLevel1):\n",
    "            if label in classes:\n",
    "                indices_class.append(indices_cluster[i])\n",
    "                datapoints.append(embedding_clusterLevel1[i])\n",
    "        \n",
    "        tic = time.time()\n",
    "        \n",
    "        hUmap.fix_datapoints(datapoints)\n",
    "        \n",
    "        embedding_clusterLevel0, y_clusterLevel0, indices_cluster = hUmap.transform(1, indices=indices_class)#indices=np.array(classes), class_based=True)\n",
    "        orig_index = hUmap.original_indices(0)\n",
    "        inds_level0 = orig_index[indices_cluster]\n",
    "        execution_humapLevel0 = time.time() - tic\n",
    "\n",
    "\n",
    "        df_humapTOP['label'+str(execution)] = hUmap.labels(2)\n",
    "        df_humapTOP['x'+str(execution)] = embedding2[:, 0]\n",
    "        df_humapTOP['y'+str(execution)] = embedding2[:, 1]\n",
    "        df_humapTOP['inds'+str(execution)] = hUmap.original_indices(2)\n",
    "\n",
    "        df_humapLevel1['label'+str(execution)] = y_clusterLevel1\n",
    "        df_humapLevel1['x'+str(execution)] = embedding_clusterLevel1[:, 0]\n",
    "        df_humapLevel1['y'+str(execution)] = embedding_clusterLevel1[:, 1]\n",
    "        df_humapLevel1['inds'+str(execution)] = inds_level1\n",
    "        \n",
    "        df_humapLevel0['label'+str(execution)] = y_clusterLevel0\n",
    "        df_humapLevel0['x'+str(execution)] = embedding_clusterLevel0[:, 0]\n",
    "        df_humapLevel0['y'+str(execution)] = embedding_clusterLevel0[:, 1]\n",
    "        df_humapLevel0['inds'+str(execution)] = inds_level0\n",
    "        \n",
    "        \n",
    "        df_hsneTOP.to_csv(\"comparison-drill/\"+dataset['name']+'/hsne_it'+str(execution)+'_TOP.csv', index=False)\n",
    "        df_hsneLevel1.to_csv(\"comparison-drill/\"+dataset['name']+'/hsne_it'+str(execution)+'_level1.csv', index=False)\n",
    "        df_hsneLevel0.to_csv(\"comparison-drill/\"+dataset['name']+'/hsne_it'+str(execution)+'_level0.csv', index=False)\n",
    "        \n",
    "        df_humapTOP.to_csv(\"comparison-drill/\"+dataset['name']+'/humap_it'+str(execution)+'_TOP.csv', index=False)\n",
    "        df_humapLevel1.to_csv(\"comparison-drill/\"+dataset['name']+'/humap_it'+str(execution)+'_level1.csv', index=False)\n",
    "        df_humapLevel0.to_csv(\"comparison-drill/\"+dataset['name']+'/humap_it'+str(execution)+'_level0.csv', index=False)\n",
    "       \n",
    "        \n",
    "        df_humapTOP = pd.DataFrame()\n",
    "        df_humapLevel1 = pd.DataFrame()\n",
    "        df_humapLevel0 = pd.DataFrame()\n",
    "\n",
    "        df_hsneTOP = pd.DataFrame()\n",
    "        df_hsneLevel1 = pd.DataFrame()\n",
    "        df_hsneLevel0 = pd.DataFrame()       \n",
    "\n",
    "        \n",
    "        \n",
    "        time_file.write('HSNE,Fit,'+str(execution_hsne_fit)+'\\n')\n",
    "        time_file.write('HUMAP,Fit,'+str(execution_humap_fit)+'\\n')        \n",
    "        \n",
    "        time_file.write('HSNE,Top,'+str(execution_hsneTOP)+'\\n')\n",
    "        time_file.write('HUMAP,Top,'+str(execution_humapTOP)+'\\n')\n",
    "        \n",
    "        time_file.write('HSNE,Level 1,'+str(execution_hsneLevel1)+'\\n')\n",
    "        time_file.write('HUMAP,Level 1,'+str(execution_humapLevel1)+'\\n')\n",
    "        \n",
    "        time_file.write('HSNE,Level 0,'+str(execution_hsneLevel0)+'\\n')\n",
    "        time_file.write('HUMAP,Level 0,'+str(execution_humapLevel0)+'\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
